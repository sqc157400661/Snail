# HTTP连接池

分析是基于go 1.13

## 为什么需要连接池

服务和服务之间的连接是开发过程中很常见的操作,为了服务解耦,减少相互依赖,增强系统稳定性,灵活性,所以会增加许许多多的服务通信链路,随着服务通信链路的增加,网络通信次数就会成倍的增长,那么随之而来的就是网络资源的消耗加剧,例如:带宽,连接数以及cpu,内存等。

- 每个连接建立时都会申请内存用来做socket buffer
- 每个连接都要做三次握手四次挥手
- 每个连接关闭时都要释放内存空间
- 并发高时,会产生大量的连接,影响系统调度,会占用太多系统资源

## 如何设计实现连接池

- 连接池的连接数目是否有限制，最大可以建立多少个连接？
- 当连接长时间没有使用，需要回收该连接吗？
- 业务请求需要获取连接时，此时若连接池无空闲连接且无法新建连接，业务需要排队等待吗？
- 排队的话又存在另外的问题，队列长度有无限制，排队时间呢？

## GoLang HTTP连接池的实现原理

### 核心结构Transport

1. Transport是实现HTTP连接请求/和连接池的核心结构，transport实现了`RoundTripper`接口， 支持HTTP、HTTPS和HTTP代理请求
2. transport的主要功能其实就是缓存了长连接，用于大量http请求场景下的连接复用，减少发送请求时TCP(TLS)连接建立的时间损耗
3. transport是协程并发安全的
4. 同时transport还能对连接做一些限制，如连接超时时间，每个host的最大连接数等。transport对长连接的缓存和控制仅限于TCP+(TLS)+HTTP1，不对HTTP2做缓存和限制。

```go
type Transport struct {
    //操作空闲连接需要获取锁
	idleMu       sync.Mutex 
	closeIdle    bool // user has requested to close all idle conns
    // *空闲连接池，key为协议目标地址等组合,最大值受maxIdleConnsPerHost限制
	idleConn     map[connectMethodKey][]*persistConn // most recently used at end
    // *等待空闲连接的队列，基于切片实现，队列大小无限制
	idleConnWait map[connectMethodKey]wantConnQueue  // waiting getConns
    // 空闲连接的LRU，用于删除最近未使用的连接
	idleLRU      connLRU

	reqMu       sync.Mutex
	reqCanceler map[*Request]func(error)

	altMu    sync.Mutex   // guards changing altProto only
	altProto atomic.Value // of nil or map[string]RoundTripper, key is URI scheme
    //排队等待建立连接需要获取锁
	connsPerHostMu   sync.Mutex
    //每个host建立的连接数
	connsPerHost     map[connectMethodKey]int
    //等待建立连接的队列，同样基于切片实现，队列大小无限制
	connsPerHostWait map[connectMethodKey]wantConnQueue // waiting getConns

	// 为request返回一个代理的url
	// If Proxy is nil or returns a nil *URL, no proxy is used.
	Proxy func(*Request) (*url.URL, error)

	/*
	 DialContext 可以控制和配置用于创建TCP连接的拨号函数，如果没有使用DialContext即DialContext为nil（并且也没有使用Dial）则会使用net包
	 它比Dial函数增加了context控制
	*/
	DialContext func(ctx context.Context, network, addr string) (net.Conn, error)

	// 创建未加密的tcp连接，废弃，请使用DialContext
	Dial func(network, addr string) (net.Conn, error)

	// DialTLS specifies an optional dial function for creating
	// TLS connections for non-proxied HTTPS requests.
	//
	// If DialTLS is nil, Dial and TLSClientConfig are used.
	//
	// If DialTLS is set, the Dial hook is not used for HTTPS
	// requests and the TLSClientConfig and TLSHandshakeTimeout
	// are ignored. The returned net.Conn is assumed to already be
	// past the TLS handshake.
	DialTLS func(network, addr string) (net.Conn, error)

	// TLSClientConfig specifies the TLS configuration to use with
	// tls.Client.
	// If nil, the default configuration is used.
	// If non-nil, HTTP/2 support may not be enabled by default.
	TLSClientConfig *tls.Config

	// TLSHandshakeTimeout specifies the maximum amount of time waiting to
	// wait for a TLS handshake. Zero means no timeout.
	TLSHandshakeTimeout time.Duration

	//禁用长连接，使用短连接
	DisableKeepAlives bool

	// DisableCompression, if true, prevents the Transport from
	// requesting compression with an "Accept-Encoding: gzip"
	// request header when the Request contains no existing
	// Accept-Encoding value. If the Transport requests gzip on
	// its own and gets a gzipped response, it's transparently
	// decoded in the Response.Body. However, if the user
	// explicitly requested gzip it is not automatically
	// uncompressed.
	DisableCompression bool

	// 最大空闲连接数
	MaxIdleConns int

	//每个目标host最大空闲连接数；默认为2（注意默认值= DefaultMaxIdleConnsPerHost）
	MaxIdleConnsPerHost int

	// 每个host可建立的最大连接数 包含空闲的、正在连接的和已经连接的，0代表没有限制
	MaxConnsPerHost int

	// 空闲连接多少时间没有使用则被关闭
	// Zero means no limit.
	IdleConnTimeout time.Duration

	// ResponseHeaderTimeout, if non-zero, specifies the amount of
	// time to wait for a server's response headers after fully
	// writing the request (including its body, if any). This
	// time does not include the time to read the response body.
	ResponseHeaderTimeout time.Duration

	// ExpectContinueTimeout, if non-zero, specifies the amount of
	// time to wait for a server's first response headers after fully
	// writing the request headers if the request has an
	// "Expect: 100-continue" header. Zero means no timeout and
	// causes the body to be sent immediately, without
	// waiting for the server to approve.
	// This time does not include the time to send the request header.
	ExpectContinueTimeout time.Duration

	// TLSNextProto specifies how the Transport switches to an
	// alternate protocol (such as HTTP/2) after a TLS NPN/ALPN
	// protocol negotiation. If Transport dials an TLS connection
	// with a non-empty protocol name and TLSNextProto contains a
	// map entry for that key (such as "h2"), then the func is
	// called with the request's authority (such as "example.com"
	// or "example.com:1234") and the TLS connection. The function
	// must return a RoundTripper that then handles the request.
	// If TLSNextProto is not nil, HTTP/2 support is not enabled
	// automatically.
	TLSNextProto map[string]func(authority string, c *tls.Conn) RoundTripper

	// ProxyConnectHeader optionally specifies headers to send to
	// proxies during CONNECT requests.
	ProxyConnectHeader Header

	// MaxResponseHeaderBytes specifies a limit on how many
	// response bytes are allowed in the server's response
	// header.
	//
	// Zero means to use a default limit.
	MaxResponseHeaderBytes int64

	// WriteBufferSize specifies the size of the write buffer used
	// when writing to the transport.
	// If zero, a default (currently 4KB) is used.
	WriteBufferSize int

	// ReadBufferSize specifies the size of the read buffer used
	// when reading from the transport.
	// If zero, a default (currently 4KB) is used.
	ReadBufferSize int

	// nextProtoOnce guards initialization of TLSNextProto and
	// h2transport (via onceSetNextProtoDefaults)
	nextProtoOnce      sync.Once
	h2transport        h2Transport // non-nil if http2 wired up
	tlsNextProtoWasNil bool        // whether TLSNextProto was nil when the Once fired

	// ForceAttemptHTTP2 controls whether HTTP/2 is enabled when a non-zero
	// Dial, DialTLS, or DialContext func or TLSClientConfig is provided.
	// By default, use of any those fields conservatively disables HTTP/2.
	// To use a custom dialer or TLS config and still attempt HTTP/2
	// upgrades, set this to true.
	ForceAttemptHTTP2 bool
}
```

可以看到，连接护着队列，都是一个map结构，而key为协议目标地址等组合，即同一种协议与同一个目标host可建立的连接或者空闲连接是有限制的。

  需要特别注意的是，MaxIdleConnsPerHost默认等于2，即与目标主机最多只维护两个空闲连接。这会导致什么呢？

  如果遇到突发流量，瞬间建立大量连接，但是回收连接时，由于最大空闲连接数的限制，该联机不能进入空闲连接池，只能直接关闭。结果是，一直新建大量连接，又关闭大量连，业务机器的TIME_WAIT连接数随之突增。

  线上有些业务架构是这样的：客户端 ===> LVS ===> Nginx ===> 服务。LVS负载均衡方案采用DR模式，LVS与Nginx配置统一VIP。此时在客户端看来，只有一个IP地址，只有一个Host。上述问题更为明显。

  最后，Transport也提供了配置DisableKeepAlives，禁用长连接，使用短连接访问第三方资源或者服务。



#### `Transport.roundTrip`是主入口

它通过传入一个request参数，由此选择一个合适的长连接来发送该request并返回response。整个流程主要分为两步：

1. 使用`getConn`函数来获得底层TCP(TLS)连接。
2. 调用`roundTrip`函数进行上层协议(HTTP)处理。

```go
// roundTrip implements a RoundTripper over HTTP.
func (t *Transport) roundTrip(req *Request) (*Response, error) {
	t.nextProtoOnce.Do(t.onceSetNextProtoDefaults)
	ctx := req.Context()
	trace := httptrace.ContextClientTrace(ctx)

	if req.URL == nil {
		req.closeBody()
		return nil, errors.New("http: nil Request.URL")
	}
	if req.Header == nil {
		req.closeBody()
		return nil, errors.New("http: nil Request.Header")
	}
	scheme := req.URL.Scheme
	isHTTP := scheme == "http" || scheme == "https"
    // 下面判断request首部的有效性
	if isHTTP {
		for k, vv := range req.Header {
			if !httpguts.ValidHeaderFieldName(k) {
				return nil, fmt.Errorf("net/http: invalid header field name %q", k)
			}
			for _, v := range vv {
				if !httpguts.ValidHeaderFieldValue(v) {
					return nil, fmt.Errorf("net/http: invalid header field value %q for key %v", v, k)
				}
			}
		}
	}
    // 判断是否使用注册的RoundTrip来处理对应的scheme。对于使用tcp+tls+http1(wss协议升级)的场景
    // 不能使用注册的roundTrip。后续代码对tcp+tls+http1或tcp+http1进行了roundTrip处理
	if t.useRegisteredProtocol(req) {
		altProto, _ := t.altProto.Load().(map[string]RoundTripper)
		if altRT := altProto[scheme]; altRT != nil {
			if resp, err := altRT.RoundTrip(req); err != ErrSkipAltProtocol {
				return resp, err
			}
		}
	}
    // 后续仅处理URL scheme为http或https的连接
	if !isHTTP {
		req.closeBody()
		return nil, &badStringError{"unsupported protocol scheme", scheme}
	}
	if req.Method != "" && !validMethod(req.Method) {
		return nil, fmt.Errorf("net/http: invalid method %q", req.Method)
	}
	if req.URL.Host == "" {
		req.closeBody()
		return nil, errors.New("http: no Host in request URL")
	}
    // 下面for循环用于在request出现错误的时候进行请求重试。但不是所有的请求失败都会被尝试，如请求被取消(errRequestCanceled)
    // 的情况是不会进行重试的。具体参见shouldRetryRequest函数
	for {
		select {
		case <-ctx.Done():
			req.closeBody()
			return nil, ctx.Err()
		default:
		}

		// treq gets modified by roundTrip, so we need to recreate for each retry.
		treq := &transportRequest{Request: req, trace: trace}
        // connectMethodForRequest函数通过输入一个request返回一个connectMethod(简称cm)，该类型通过
        // {proxyURL,targetScheme,tartgetAddr,onlyH1},即{代理URL，server端的scheme，server的地址，是否HTTP1}
        // 来表示一个请求。一个符合connectMethod描述的request将会在Transport.idleConn中匹配到一类长连接。
		cm, err := t.connectMethodForRequest(treq)
		if err != nil {
			req.closeBody()
			return nil, err
		}

	
        // 获取一条长连接，如果连接池中有现成的连接则直接返回，否则返回一条新建的连接。该连接可能是HTTP2格式的，存放在persistCnn.alt中,
        // 使用其自注册的RoundTrip处理。该函数描述参见下面内容。
        // 从getConn的实现中可以看到，一个请求只能在idle的连接上执行，反之一条连接只能同时处理一个请求。
		pconn, err := t.getConn(treq, cm)
         // 如果获取底层连接失败，无法继续上层协议的请求，直接返回错误
		if err != nil {
            // 每个request都会在getConn中设置reqCanceler，获取连接失败，清空设置
			t.setReqCanceler(req, nil)
			req.closeBody()
			return nil, err
		}

		var resp *Response
        // pconn.alt就是从Transport.TLSNextProto中获取的，它表示TLS之上的协议，如HTTP2。从persistConn.alt的注释中可以看出
        // 目前alt仅支持HTTP2协议，后续可能会支持更多协议。
		if pconn.alt != nil {
			// HTTP2处理，使用HTTP2时，由于不缓存HTTP2连接，不对其做限制
			t.setReqCanceler(req, nil) // not cancelable with CancelRequest
			resp, err = pconn.alt.RoundTrip(req)
		} else {
            // pconn.roundTrip中做了比较复杂的处理，该函数用于发送request并返回response。
            // 通过writeLoop发送request，通过readLoop返回response
			resp, err = pconn.roundTrip(treq)
		}
        // 如果成功返回response，则整个处理结束.
		if err == nil {
			return resp, nil
		}
		if http2isNoCachedConnError(err) {
			t.removeIdleConn(pconn)
		} else if !pconn.shouldRetryRequest(req, err) {
			// Issue 16465: return underlying net.Conn.Read error from peek,
			// as we've historically done.
			if e, ok := err.(transportReadFromServerError); ok {
				err = e.err
			}
			return nil, err
		}
		testHookRoundTripRetried()

		// Rewind the body if we're able to.
        // 用于重定向场景
		if req.GetBody != nil {
			newReq := *req
			var err error
			newReq.Body, err = req.GetBody()
			if err != nil {
				return nil, err
			}
			req = &newReq
		}
	}
}
```

#### getConn连接获取

需要重点关注的是`t.getConn`这个函数。`t.getConn`的作用是获取一个长链接，这个长链接有2种方式：

1. 从空闲的连接池中获取 （persistConn对象）；调用 `queueForIdleConn`方法
2. 当连接池中无法获取到时会新建一条连接；调用 `queueForDial`方法

下面看一下这个函数的关键实现细节:

```go
func (t *Transport) getConn(treq *transportRequest, cm connectMethod) (pc *persistConn, err error) {
	req := treq.Request
	trace := treq.trace
	ctx := req.Context()
	if trace != nil && trace.GetConn != nil {
		trace.GetConn(cm.addr())
	}

	w := &wantConn{
		cm:         cm,
		key:        cm.key(),
		ctx:        ctx,
		ready:      make(chan struct{}, 1),
		beforeDial: testHookPrePendingDial,
		afterDial:  testHookPostPendingDial,
	}
	defer func() {
		if err != nil {
			w.cancel(t, err)
		}
	}()
    // 从连接池中找一条合适的连接，如果找到则返回该连接，否则新建连接
	// Queue for idle connection.
	if delivered := t.queueForIdleConn(w); delivered {
		pc := w.pc
		if trace != nil && trace.GotConn != nil {
			trace.GotConn(pc.gotIdleConnTrace(pc.idleAt))
		}
		// set request canceler to some non-nil function so we
		// can detect whether it was cleared between now and when
		// we enter roundTrip
		t.setReqCanceler(req, func(error) {})
		return pc, nil
	}

	cancelc := make(chan error, 1)
	t.setReqCanceler(req, func(err error) { cancelc <- err })

    //新建连接
	// Queue for permission to dial.
	t.queueForDial(w)

	// Wait for completion or cancellation.
	select {
	case <-w.ready:
		// Trace success but only for HTTP/1.
		// HTTP/2 calls trace.GotConn itself.
		if w.pc != nil && w.pc.alt == nil && trace != nil && trace.GotConn != nil {
			trace.GotConn(httptrace.GotConnInfo{Conn: w.pc.conn, Reused: w.pc.isReused()})
		}
		if w.err != nil {
			// If the request has been cancelled, that's probably
			// what caused w.err; if so, prefer to return the
			// cancellation error (see golang.org/issue/16049).
			select {
			case <-req.Cancel:
				return nil, errRequestCanceledConn
			case <-req.Context().Done():
				return nil, req.Context().Err()
			case err := <-cancelc:
				if err == errRequestCanceled {
					err = errRequestCanceledConn
				}
				return nil, err
			default:
				// return below
			}
		}
		return w.pc, w.err
    //超时被取消
	case <-req.Cancel:
		return nil, errRequestCanceledConn
	case <-req.Context().Done():
		return nil, req.Context().Err()
	case err := <-cancelc:
		if err == errRequestCanceled {
			err = errRequestCanceledConn
		}
		return nil, err
	}
}
```

![img](D:\www\Snail\Go专题系列\images\hU5ivrFRwsUNxeG68kc8.svg)

##### 等待空闲连接 `queueForIdleConn`

```go

func (t *Transport) queueForIdleConn(w *wantConn) (delivered bool) {
	if t.DisableKeepAlives {
		return false
	}

	t.idleMu.Lock()
	defer t.idleMu.Unlock()

	// Stop closing connections that become idle - we might want one.
	// (That is, undo the effect of t.CloseIdleConnections.)
	t.closeIdle = false

	if w == nil {
		// Happens in test hook.
		return false
	}

	// Look for most recently-used idle connection.
	if list, ok := t.idleConn[w.key]; ok {
		stop := false
		delivered := false
		for len(list) > 0 && !stop {
			pconn := list[len(list)-1]
			if pconn.isBroken() {
				// persistConn.readLoop has marked the connection broken,
				// but Transport.removeIdleConn has not yet removed it from the idle list.
				// Drop on floor on behalf of Transport.removeIdleConn.
				list = list[:len(list)-1]
				continue
			}
            //分发连接到wantConn
			delivered = w.tryDeliver(pconn, nil)
			if delivered {
				if pconn.alt != nil {
					// HTTP/2: multiple clients can share pconn.
					// Leave it in the list.
				} else {
					// HTTP/1: only one client can use pconn.
					// Remove it from the list.
					t.idleLRU.remove(pconn)
					list = list[:len(list)-1]
				}
			}
			stop = true
		}
		if len(list) > 0 {
			t.idleConn[w.key] = list
		} else {
			delete(t.idleConn, w.key)
		}
		if stop {
			return delivered
		}
	}

    //排队等待空闲连接
	// Register to receive next connection that becomes idle.
	if t.idleConnWait == nil {
		t.idleConnWait = make(map[connectMethodKey]wantConnQueue)
	}
	q := t.idleConnWait[w.key]
	q.cleanFront()
	q.pushBack(w)
	t.idleConnWait[w.key] = q
	return false
}
```

##### 排队等待新建连接的逻辑`queueForDial`

```
func (t *Transport) queueForDial(w *wantConn) {
	w.beforeDial()
	//如果没有限制最大连接数，直接建立连接
	if t.MaxConnsPerHost <= 0 {
		go t.dialConnFor(w)
		return
	}

	t.connsPerHostMu.Lock()
	defer t.connsPerHostMu.Unlock()
    //如果没超过连接数限制，直接建立连接
	if n := t.connsPerHost[w.key]; n < t.MaxConnsPerHost {
		if t.connsPerHost == nil {
			t.connsPerHost = make(map[connectMethodKey]int)
		}
		t.connsPerHost[w.key] = n + 1
		go t.dialConnFor(w)
		return
	}
    //排队等待连接建立
	if t.connsPerHostWait == nil {
		t.connsPerHostWait = make(map[connectMethodKey]wantConnQueue)
	}
	q := t.connsPerHostWait[w.key]
	q.cleanFront()
	q.pushBack(w)
	t.connsPerHostWait[w.key] = q
}
```

### 连接回收`tryPutIdleConn`

请求处理完成后，通过`tryPutIdleConn`将连接放回连接池；这时候如果存在等待空闲连接的协程，则需要分发复用该连接。另外，在回收连接时，还需要校验空闲连接数目是否超过限制：

```go
func (t *Transport) tryPutIdleConn(pconn *persistConn) error {
    //禁用长连接；或者最大空闲连接数不合法,返回错误,用于后续进行连接的关闭
	if t.DisableKeepAlives || t.MaxIdleConnsPerHost < 0 {
		return errKeepAlivesDisabled
	}
	if pconn.isBroken() {
		return errConnBroken
	}
	pconn.markReused()

	t.idleMu.Lock()
	defer t.idleMu.Unlock()

    // 如果是HTTP2连接，则直接返回，不缓存该连接
	// HTTP/2 (pconn.alt != nil) connections do not come out of the idle list,
	// because multiple goroutines can use them simultaneously.
	// If this is an HTTP/2 connection being “returned,” we're done.
	if pconn.alt != nil && t.idleLRU.m[pconn] != nil {
		return nil
	}

	// Deliver pconn to goroutine waiting for idle connection, if any.
	// (They may be actively dialing, but this conn is ready first.
	// Chrome calls this socket late binding.
	// See https://insouciant.org/tech/connection-management-in-chromium/.)
	key := pconn.cacheKey
	if q, ok := t.idleConnWait[key]; ok {
		done := false
		if pconn.alt == nil {
            //如果等待队列不为空，分发连接
			// HTTP/1.
			// Loop over the waiting list until we find a w that isn't done already, and hand it pconn.
			for q.len() > 0 {
				w := q.popFront()
				if w.tryDeliver(pconn, nil) {
					done = true
					break
				}
			}
		} else {
            //如果等待队列不为空，分发连接
			// HTTP/2.
			// Can hand the same pconn to everyone in the waiting list,
			// and we still won't be done: we want to put it in the idle
			// list unconditionally, for any future clients too.
			for q.len() > 0 {
				w := q.popFront()
				w.tryDeliver(pconn, nil)
			}
		}
		if q.len() == 0 {
			delete(t.idleConnWait, key)
		} else {
			t.idleConnWait[key] = q
		}
		if done {
			return nil
		}
	}

	if t.closeIdle {
		return errCloseIdle
	}
	if t.idleConn == nil {
		t.idleConn = make(map[connectMethodKey][]*persistConn)
	}
    //空闲连接数目超过限制，默认为DefaultMaxIdleConnsPerHost=2，返回错误
	idles := t.idleConn[key]
	if len(idles) >= t.maxIdleConnsPerHost() {
		return errTooManyIdleHost
	}
    // 需要缓存的连接与连接池中已有的重复，系统退出（这种情况下系统已经发生了混乱，直接退出）
	for _, exist := range idles {
		if exist == pconn {
			log.Fatalf("dup idle pconn %p in freelist", pconn)
		}
	}
    // 添加回收连接
	t.idleConn[key] = append(idles, pconn)
	t.idleLRU.add(pconn)
    // 受MaxIdleConns的限制，添加策略变为：添加新的连接，删除最老的连接。
    // MaxIdleConns限制了所有类型的idle状态的最大连接数目，而MaxIdleConnsPerHost限制了host上单一类型的最大连接数目
    // idleLRU中保存了所有的连接，此处的作用为，找出最老的连接并移除
	if t.MaxIdleConns != 0 && t.idleLRU.len() > t.MaxIdleConns {
		oldest := t.idleLRU.removeOldest()
		oldest.close(errTooManyIdle)
		t.removeIdleConnLocked(oldest)
	}

    // 为新添加的连接设置超时时间
	// Set idle timer, but only for HTTP/1 (pconn.alt == nil).
	// The HTTP/2 implementation manages the idle timer itself
	// (see idleConnTimeout in h2_bundle.go).
	if t.IdleConnTimeout > 0 && pconn.alt == nil {
		if pconn.idleTimer != nil {
            // 如果该连接是被释放的，则重置超时时间
			pconn.idleTimer.Reset(t.IdleConnTimeout)
		} else {
            // 如果该连接时新建的，则设置超时时间并设置超时动作pconn.closeConnIfStillIdle
            // closeConnIfStillIdle用于释放连接，从Transport.idleLRU和Transport.idleConn中移除并关闭该连接
			pconn.idleTimer = time.AfterFunc(t.IdleConnTimeout, pconn.closeConnIfStillIdle)
		}
	}
	pconn.idleAt = time.Now()
	return nil
}
```

注意：空闲连接超时关闭使用`pconn.idleTimer = time.AfterFunc(t.IdleConnTimeout, pconn.closeConnIfStillIdle)`

### 排队队列怎么实现

怎么实现队列模型呢？很简单，可以基于切片：

```
queue    []*wantConn

//入队
queue = append(queue, w)

//出队
v := queue[0]
queue[0] = nil
queue = queue[1:]
```

  这样有什么问题吗？随着频繁的入队与出队操作，切片queue的底层数组，会有大量空间无法复用而造成浪费。除非该切片执行了扩容操作。

  Golang在实现队列时，使用了两个切片head和tail；head切片用于出队操作，tail切片用于入队操作；出队时，如果head切片为空，则交换head与tail。通过这种方式，Golang实现了底层数组空间的复用。

```
func (q *wantConnQueue) pushBack(w *wantConn) {
    q.tail = append(q.tail, w)
}

func (q *wantConnQueue) popFront() *wantConn {
    if q.headPos >= len(q.head) {
        if len(q.tail) == 0 {
            return nil
        }
        // Pick up tail as new head, clear tail.
        q.head, q.headPos, q.tail = q.tail, 0, q.head[:0]
    }
    w := q.head[q.headPos]
    q.head[q.headPos] = nil
    q.headPos++
    return w
}
```

https://www.cnblogs.com/charlieroro/p/11409153.html

https://segmentfault.com/a/1190000023033193?utm_source=tag-newest

https://blog.csdn.net/qq_21514303/article/details/87794750

https://draveness.me/golang/docs/part4-advanced/ch09-stdlib/golang-net-http/#922-%E5%AE%A2%E6%88%B7%E7%AB%AF



需要搞懂的：

TIME_WAIT：https://www.cnblogs.com/rexcheny/p/11143128.html



https://segmentfault.com/a/1190000019736068



可能遇到的问题

https://blog.csdn.net/luckydoit/article/details/86510618

https://www.dazhuanlan.com/2019/12/13/5df2e64445102/

http://xiaorui.cc/archives/5056